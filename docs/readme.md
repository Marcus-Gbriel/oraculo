# ğŸ”® Sistema OrÃ¡culo - Guia RÃ¡pido

## âœ… Status Atual: SISTEMA TOTALMENTE FUNCIONAL

O Sistema OrÃ¡culo estÃ¡ **completo e operacional** com as seguintes funcionalidades:

### ğŸ¯ Funcionalidades Principais

1. **âœ… RAG Completo** - Retrieval Augmented Generation totalmente local
2. **âœ… 7 Modelos LLM** - Gerenciamento integrado de modelos GPT4All
3. **âœ… GPU Acelerada** - Suporte automÃ¡tico a NVIDIA CUDA
4. **âœ… Interface Limpa** - Logs organizados, console profissional
5. **âœ… Alta PrecisÃ£o** - Temperature 0.2, prompt otimizado
6. **âœ… Logs Detalhados** - Pasta logs/ com arquivos diÃ¡rios

## ğŸš€ InÃ­cio RÃ¡pido

### 1. InstalaÃ§Ã£o AutomÃ¡tica (Windows)

```cmd
execute.bat
# Escolha: 1 - Instalar dependÃªncias
```

### 2. Executar o Sistema

```cmd
python index.py
# ou
execute.bat â†’ 2 - Executar Sistema
```

### 3. Menu Principal

**ğŸ“š DOCUMENTOS:**
- 1ï¸âƒ£ Indexar documentos
- 2ï¸âƒ£ Fazer pergunta
- 3ï¸âƒ£ Modo interativo
- 4ï¸âƒ£ Ver estatÃ­sticas
- 5ï¸âƒ£ Reindexar

**ğŸ¤– MODELOS LLM:**
- 6ï¸âƒ£ Listar modelos (7 disponÃ­veis)
- 7ï¸âƒ£ Ver detalhes de modelo
- 8ï¸âƒ£ Selecionar modelo ativo

## ğŸ“‹ Requisitos

### âœ… Compatibilidade Python

| VersÃ£o | Status | Notas |
|--------|--------|-------|
| 3.10.x | âœ… Excelente | Totalmente testado |
| 3.11.x | âœ… Excelente | Totalmente testado |
| 3.12.x | âœ… Excelente | Totalmente testado |
| 3.13.x | âœ… Ã“timo | **VersÃ£o atual recomendada** |
| 3.14.x | âš ï¸ Evitar | Bibliotecas sem suporte completo |

### ğŸ’» Hardware Recomendado

**MÃ­nimo:**
- CPU: Dual-core 2.0 GHz
- RAM: 8 GB
- Disco: 10 GB livres
- GPU: Nenhuma (funciona em CPU)

**Recomendado:**
- CPU: Quad-core 3.0 GHz+
- RAM: 16 GB
- Disco: 20 GB livres (para mÃºltiplos modelos)
- GPU: NVIDIA RTX 2060+ (6GB VRAM)

## ğŸ¤– Modelos LLM DisponÃ­veis

O sistema usa **GPT4All** - 100% Python, sem compiladores!

# 3. Executar instalador
execute.bat

# 4. Escolher opÃ§Ã£o 1
```

## âš¡ Sistema FuncionarÃ¡ Sem LLM

**Importante**: Se `llama-cpp-python` falhar na instalaÃ§Ã£o:
- âœ… O sistema AINDA funcionarÃ¡
- âœ… Todos os documentos serÃ£o indexados
- âœ… Busca semÃ¢ntica funcionarÃ¡ perfeitamente
- âš ï¸ Respostas serÃ£o limitadas (modo teste)

Para respostas completas, vocÃª pode:
1. Instalar Python 3.12 (recomendado)
2. Ou baixar modelos LLM via API (Ollama, LM Studio)

## ğŸ“ Perguntas Frequentes

**P: Preciso desinstalar Python 3.14?**
R: NÃ£o necessariamente. VocÃª pode ter mÃºltiplas versÃµes. Use `py -3.12` ou `python3.12`.


| Modelo | Tamanho | Qualidade | Ideal Para |
|--------|---------|-----------|------------|
| **Mistral 7B OpenOrca** | 3.8 GB | â­â­â­â­â­ | Uso geral (PadrÃ£o) |
| **Mistral 7B Instruct** | 3.8 GB | â­â­â­â­â­ | PrecisÃ£o literal |
| **Orca 2 7B** | 3.8 GB | â­â­â­â­ | AnÃ¡lise tÃ©cnica |
| **Nous Hermes 13B** | 7.3 GB | â­â­â­â­â­ | MÃ¡xima qualidade |
| **GPT4All Falcon** | 3.9 GB | â­â­â­â­ | Versatilidade |
| **WizardLM 13B** | 7.3 GB | â­â­â­â­â­ | RaciocÃ­nio complexo |
| **Orca Mini 3B** | 1.8 GB | â­â­â­ | PCs fracos |

ğŸ’¡ **Download automÃ¡tico** na primeira execuÃ§Ã£o!

## ğŸ¨ Recursos AvanÃ§ados

### ğŸ“Š Sistema de Logs

**Console:** Interface limpa, apenas o essencial
**Arquivos:** `logs/oraculo_YYYYMMDD.log` - Completo e detalhado

```
logs/
â”œâ”€â”€ oraculo_20251217.log  â† Hoje
â”œâ”€â”€ oraculo_20251216.log  â† Ontem
â””â”€â”€ oraculo_20251215.log  â† Anteontem
```

### âš™ï¸ ConfiguraÃ§Ãµes (config.json)

```json
{
  "selected_model": "mistral-7b-openorca.Q4_0.gguf",
  "temperature": 0.2,
  "max_tokens": 512
}
```

### ğŸ¯ PrecisÃ£o Otimizada

- **Temperature:** 0.2 (respostas determinÃ­sticas)
- **Chunks:** 5 documentos relevantes (antes: 3)
- **Contexto:** 2500 chars por chunk (antes: 1500)
- **Prompt:** InstruÃ§Ãµes rigorosas para evitar "alucinaÃ§Ãµes"

### ğŸ§ª Benchmark de Qualidade

Incluso: `BENCHMARK-PERGUNTAS.md`
- 25+ perguntas de teste
- 7 categorias (contradiÃ§Ãµes, ambiguidades, etc)
- Sistema de pontuaÃ§Ã£o

## ğŸ“š DocumentaÃ§Ã£o Completa

```
docs/
â”œâ”€â”€ README.md              # VisÃ£o geral
â”œâ”€â”€ LEIA-ME-PRIMEIRO.md   # Este arquivo
â”œâ”€â”€ INSTALLATION.md        # InstalaÃ§Ã£o detalhada
â”œâ”€â”€ ARCHITECTURE.md        # Arquitetura do sistema
â””â”€â”€ GPT4ALL-IMPLEMENTADO.md # Detalhes do GPT4All
```

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro: "Python not found"
```cmd
# Reinstale Python e marque "Add to PATH"
# Ou use: py -3.13 index.py
```

### Erro: "Failed to load DLL"
âœ… **Normal!** SÃ£o warnings do GPT4All tentando diferentes versÃµes CUDA.
O sistema funciona perfeitamente, apenas ignore.

### Erro: "No module named X"
```cmd
pip install -r requirements.txt
```

### GPU nÃ£o detectada
```cmd
# Verifique CUDA
nvidia-smi

# Instale PyTorch com CUDA (opcional)
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### Respostas imprecisas
1. Use Menu â†’ OpÃ§Ã£o 8 para trocar modelo
2. Teste Mistral 7B Instruct (mais preciso)
3. Use BENCHMARK-PERGUNTAS.md para testar

## â“ FAQ

**P: Funciona totalmente offline?**
R: âœ… Sim! 100% local apÃ³s baixar o modelo.

**P: Quanto tempo demora para baixar o modelo?**
R: ~10-20 minutos (3.8 GB), dependendo da conexÃ£o.

**P: Posso usar mÃºltiplos modelos?**
R: âœ… Sim! Baixe vÃ¡rios e troque pelo menu (opÃ§Ã£o 8).

**P: GPU Ã© obrigatÃ³ria?**
R: âŒ NÃ£o! Funciona em CPU (mais lento, mas funciona).

**P: Quantos documentos posso indexar?**
R: Sem limite! Depende apenas do espaÃ§o em disco.

**P: Suporta portuguÃªs?**
R: âœ… Perfeitamente! Embeddings multilÃ­ngues + modelos em PT.

## ğŸ“ PrÃ³ximos Passos

1. âœ… Execute `python index.py`
2. âœ… OpÃ§Ã£o 1 - Indexar documentos de teste
3. âœ… OpÃ§Ã£o 3 - Modo interativo
4. âœ… Teste com perguntas do BENCHMARK-PERGUNTAS.md
5. âœ… OpÃ§Ã£o 6 - Ver modelos disponÃ­veis
6. âœ… Adicione seus documentos em `training/`

## ğŸ“ Suporte

- **Logs:** Verifique `logs/oraculo_YYYYMMDD.log`
- **DocumentaÃ§Ã£o:** Consulte arquivos em `docs/`
- **Problemas:** Revise erros nos logs detalhados

---

**Sistema OrÃ¡culo v1.0.0**
InteligÃªncia Artificial Local para Consulta de Documentos ğŸ”®

**Ãšltima atualizaÃ§Ã£o:** 17/12/2025  
**Status:** âœ… Totalmente funcional  
**Recursos:** 7 modelos LLM, GPU acelerada, logs organizados, interface limpa
